name: Koto Ultimate Build
on: workflow_dispatch

jobs:
  build:
    runs-on: macos-15
    steps:
      - uses: actions/checkout@v4
      
      # ---------------------------------------------------
      # 1. INJECT THE ROBUST APP CODE
      # ---------------------------------------------------
      - name: Write App Code
        run: |
          cat <<'EOF' > App.swift
          import SwiftUI
          import Translation
          import Speech
          import AVFoundation

          @main
          struct KotoApp: App {
              init() {
                  UITabBar.appearance().barTintColor = .black
                  UITabBar.appearance().backgroundColor = .black
              }
              var body: some Scene {
                  WindowGroup { MainView().preferredColorScheme(.dark) }
              }
          }

          struct MainView: View {
              var body: some View {
                  TabView {
                      TranslatorScreen().tabItem { Label("Voice", systemImage: "mic.fill") }
                      HistoryScreen().tabItem { Label("History", systemImage: "clock.fill") }
                  }.accentColor(.blue)
              }
          }

          struct TranslatorScreen: View {
              @State private var text = ""
              @State private var result = ""
              @State private var status = "Ready" // DEBUG STATUS
              @State private var isListening = false
              @State private var config: TranslationSession.Configuration?
              @AppStorage("history_json") private var historyJSON = "[]"
              
              private let speech = SpeechManager()
              private let voice = AVSpeechSynthesizer()
              private let haptic = UIImpactFeedbackGenerator(style: .heavy)

              var body: some View {
                  ZStack {
                      // Beautiful Dark Gradient
                      LinearGradient(colors: [Color(red: 0.05, green: 0.05, blue: 0.1), .black], startPoint: .top, endPoint: .bottom).ignoresSafeArea()
                      
                      VStack(spacing: 20) {
                          // HEADER
                          HStack {
                              Text("KOTO AI").font(.title2).fontWeight(.black).foregroundStyle(.white)
                              Spacer()
                              Text("PRO").font(.caption).fontWeight(.bold).padding(6).background(.blue).cornerRadius(6)
                          }.padding(.horizontal, 24).padding(.top, 40)

                          Spacer()

                          // RESULT CARD
                          if !result.isEmpty {
                              VStack(alignment: .leading, spacing: 15) {
                                  Text(result).font(.system(size: 32, weight: .bold, design: .rounded)).foregroundStyle(.white)
                                  HStack {
                                      Button(action: { speak(result) }) {
                                          Label("Speak", systemImage: "speaker.wave.2.fill")
                                              .font(.caption.bold()).padding(8).background(.white.opacity(0.1)).clipShape(Capsule())
                                      }
                                      Spacer()
                                  }
                              }
                              .padding(24).background(.ultraThinMaterial).cornerRadius(24).padding(.horizontal)
                          } else if !text.isEmpty {
                              Text(text).font(.title3).foregroundStyle(.gray).multilineTextAlignment(.center).padding()
                          }

                          Spacer()

                          // STATUS LOG (So you know it's working)
                          Text(status).font(.caption).foregroundStyle(.gray).padding(.bottom, 10)

                          // MIC BUTTON
                          Button(action: toggleMic) {
                              ZStack {
                                  Circle().fill(isListening ? .red : .blue).frame(width: 100, height: 100).blur(radius: isListening ? 20 : 0).opacity(0.5)
                                  Circle().fill(LinearGradient(colors: [isListening ? .red : .blue, .purple], startPoint: .topLeading, endPoint: .bottomTrailing))
                                      .frame(width: 80, height: 80)
                                      .overlay(Image(systemName: isListening ? "stop.fill" : "mic.fill").font(.largeTitle).foregroundStyle(.white))
                              }
                          }
                          .padding(.bottom, 40)
                      }
                  }
                  // TRANSLATION TRIGGER
                  .translationTask(config) { session in
                      do {
                          status = "Translating..."
                          let r = try await session.translate(text)
                          result = r.targetText
                          status = "Done"
                          haptic.impactOccurred()
                          speak(result)
                          addToHistory(original: text, translated: result)
                      } catch {
                          status = "Error: \(error.localizedDescription)"
                      }
                  }
              }

              func toggleMic() {
                  haptic.impactOccurred()
                  if isListening {
                      isListening = false
                      speech.stop()
                      if !text.isEmpty {
                          status = "Processing..."
                          config = .init(source: .init(identifier: "en"), target: .init(identifier: "ja"))
                      } else {
                          status = "No speech detected"
                      }
                  } else {
                      text = ""; result = ""; isListening = true
                      status = "Listening..."
                      speech.start { t in text = t }
                  }
              }

              func speak(_ t: String) {
                  let u = AVSpeechUtterance(string: t)
                  u.voice = AVSpeechSynthesisVoice(language: "ja-JP")
                  u.rate = 0.5
                  voice.speak(u)
              }
              
              func addToHistory(original: String, translated: String) {
                  struct Item: Codable { let original: String; let translated: String }
                  var list = (try? JSONDecoder().decode([Item].self, from: historyJSON.data(using: .utf8)!)) ?? []
                  list.insert(Item(original: original, translated: translated), at: 0)
                  if let data = try? JSONEncoder().encode(list) { historyJSON = String(data: data, encoding: .utf8) ?? "[]" }
              }
          }

          struct HistoryScreen: View {
              @AppStorage("history_json") private var historyJSON = "[]"
              var body: some View {
                  NavigationView {
                      List {
                          let list = (try? JSONDecoder().decode([HItem].self, from: historyJSON.data(using: .utf8)!)) ?? []
                          ForEach(list, id: \.translated) { item in
                              VStack(alignment: .leading) {
                                  Text(item.original).font(.caption).foregroundStyle(.gray)
                                  Text(item.translated).font(.headline).foregroundStyle(.white)
                              }
                              .listRowBackground(Color.white.opacity(0.1))
                          }
                      }
                      .navigationTitle("History")
                      .scrollContentBackground(.hidden)
                      .background(Color.black.ignoresSafeArea())
                  }
              }
              struct HItem: Codable { let original: String; let translated: String }
          }

          class SpeechManager {
              let r = SFSpeechRecognizer(locale: Locale(identifier: "en-US"))
              var req: SFSpeechAudioBufferRecognitionRequest?
              var task: SFSpeechRecognitionTask?
              let eng = AVAudioEngine()
              
              func start(on: @escaping (String)->Void) {
                  // Setup Audio Session
                  let s = AVAudioSession.sharedInstance()
                  try? s.setCategory(.record, mode: .measurement, options: .duckOthers)
                  try? s.setActive(true, options: .notifyOthersOnDeactivation)
                  
                  req = SFSpeechAudioBufferRecognitionRequest()
                  // REMOVED 'requiresOnDeviceRecognition' TO PREVENT CRASHES
                  
                  let node = eng.inputNode
                  let format = node.outputFormat(forBus: 0)
                  node.removeTap(onBus: 0) // Safety Check
                  node.installTap(onBus: 0, bufferSize: 1024, format: format) { b, _ in self.req?.append(b) }
                  
                  eng.prepare()
                  try? eng.start()
                  
                  task = r?.recognitionTask(with: req!) { res, _ in 
                      if let res = res { on(res.bestTranscription.formattedString) }
                  }
              }
              func stop() { eng.stop(); eng.inputNode.removeTap(onBus: 0); req?.endAudio(); task?.cancel() }
          }
          EOF

      # ---------------------------------------------------
      # 2. GENERATE CONFIG
      # ---------------------------------------------------
      - name: Write Config
        run: |
          echo '{"name":"KotoAI","targets":{"KotoAI":{"type":"application","platform":"iOS","deploymentTarget":"18.0","sources":["App.swift"],"settings":{"PRODUCT_BUNDLE_IDENTIFIER":"com.koto.ai","CODE_SIGNING_ALLOWED":"NO"},"info":{"path":"Info.plist","properties":{"NSMicrophoneUsageDescription":"Mic","NSSpeechRecognitionUsageDescription":"Speech"}}}}}' > project.json
          echo '<?xml version="1.0"?><!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd"><plist version="1.0"><dict></dict></plist>' > Info.plist

      # ---------------------------------------------------
      # 3. BUILD
      # ---------------------------------------------------
      - name: Build
        run: |
          brew install xcodegen
          xcodegen generate --spec project.json
          xcodebuild archive -project KotoAI.xcodeproj -scheme KotoAI -configuration Release -archivePath build.xcarchive CODE_SIGNING_ALLOWED=NO CODE_SIGNING_REQUIRED=NO
          mkdir Payload
          cp -r build.xcarchive/Products/Applications/KotoAI.app Payload/
          zip -r KotoAI.ipa Payload

      - uses: actions/upload-artifact@v4
        with:
          name: KotoAI-Ultimate
          path: KotoAI.ipa


