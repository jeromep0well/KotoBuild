name: Koto Premium Build
on: workflow_dispatch

jobs:
  build:
    runs-on: macos-15
    steps:
      - uses: actions/checkout@v4
      
      # ---------------------------------------------------
      # 1. INJECT THE PREMIUM UI CODE
      # ---------------------------------------------------
      - name: Write Premium App
        run: |
          cat <<'EOF' > App.swift
          import SwiftUI
          import Translation
          import Speech
          import AVFoundation

          // --- APP ENTRY ---
          @main
          struct KotoApp: App {
              init() {
                  // Force Dark Mode for that "Premium" look
                  UITabBar.appearance().barTintColor = .black
                  UITabBar.appearance().backgroundColor = .black
              }
              var body: some Scene {
                  WindowGroup {
                      MainView().preferredColorScheme(.dark)
                  }
              }
          }

          struct MainView: View {
              var body: some View {
                  TabView {
                      TranslatorScreen().tabItem { Label("Voice", systemImage: "mic.fill") }
                      HistoryScreen().tabItem { Label("History", systemImage: "clock.fill") }
                  }.accentColor(.blue)
              }
          }

          // --- MAIN TRANSLATOR SCREEN ---
          struct TranslatorScreen: View {
              @State private var text = ""
              @State private var result = ""
              @State private var isListening = false
              @State private var config: TranslationSession.Configuration?
              @AppStorage("history_json") private var historyJSON = "[]"
              
              private let speech = NeuralMic()
              private let voice = AVSpeechSynthesizer()
              private let haptic = UIImpactFeedbackGenerator(style: .heavy)

              var body: some View {
                  ZStack {
                      // 1. BACKGROUND GRADIENT (Matches the original web look)
                      LinearGradient(colors: [Color(red: 0.1, green: 0.1, blue: 0.2), .black], startPoint: .top, endPoint: .bottom).ignoresSafeArea()
                      
                      // Ambient Glow
                      Circle().fill(Color.blue.opacity(0.1)).frame(width: 300).blur(radius: 60).offset(y: -200)

                      VStack(spacing: 20) {
                          // 2. HEADER
                          HStack {
                              VStack(alignment: .leading) {
                                  Text("VOICE AI").font(.caption).fontWeight(.black).foregroundStyle(.blue).tracking(2)
                                  Text("Koto AI").font(.largeTitle).fontWeight(.bold).foregroundStyle(.white)
                              }
                              Spacer()
                              Image(systemName: "waveform.circle.fill").font(.largeTitle).foregroundStyle(.blue)
                          }.padding(.horizontal, 24).padding(.top, 40)

                          Spacer()

                          // 3. TRANSLATION CARD (Glassmorphism)
                          if !result.isEmpty {
                              VStack(alignment: .leading, spacing: 16) {
                                  HStack {
                                      Label("AI Result", systemImage: "sparkles").font(.caption).fontWeight(.bold).foregroundStyle(.blue)
                                      Spacer()
                                      Button(action: { speak(result) }) {
                                          Image(systemName: "speaker.wave.2.fill").foregroundStyle(.white.opacity(0.8))
                                      }
                                  }
                                  Text(result)
                                      .font(.system(size: 32, weight: .bold, design: .rounded))
                                      .foregroundStyle(.white)
                                      .multilineTextAlignment(.leading)
                                  
                                  Divider().background(.white.opacity(0.2))
                                  
                                  Text("Japanese â€¢ Polite Form").font(.caption).foregroundStyle(.gray)
                              }
                              .padding(24)
                              .background(.ultraThinMaterial)
                              .clipShape(RoundedRectangle(cornerRadius: 24))
                              .overlay(RoundedRectangle(cornerRadius: 24).stroke(.white.opacity(0.1), lineWidth: 1))
                              .padding(.horizontal)
                              .transition(.move(edge: .bottom).combined(with: .opacity))
                          } else if !text.isEmpty {
                              // Live Transcript
                              Text(text)
                                  .font(.title2)
                                  .foregroundStyle(.gray)
                                  .multilineTextAlignment(.center)
                                  .padding()
                          }

                          Spacer()

                          // 4. THE GLOWING ORB BUTTON
                          VStack(spacing: 20) {
                              Button(action: toggleMic) {
                                  ZStack {
                                      // Outer Pulse
                                      if isListening {
                                          Circle().fill(Color.red.opacity(0.2))
                                              .frame(width: 140, height: 140)
                                              .scaleEffect(1.2).blur(radius: 20)
                                      }
                                      
                                      // Core Orb
                                      Circle()
                                          .fill(LinearGradient(colors: [isListening ? .red : .blue, isListening ? .orange : .indigo], startPoint: .topLeading, endPoint: .bottomTrailing))
                                          .frame(width: 100, height: 100)
                                          .overlay(
                                              Image(systemName: isListening ? "stop.fill" : "mic.fill")
                                                  .font(.system(size: 36, weight: .bold))
                                                  .foregroundStyle(.white)
                                          )
                                          .shadow(color: (isListening ? .red : .blue).opacity(0.5), radius: 20, x: 0, y: 10)
                                  }
                              }
                              .buttonStyle(PlainButtonStyle())
                              
                              Text(isListening ? "LISTENING..." : "TAP TO SPEAK")
                                  .font(.caption).fontWeight(.black).foregroundStyle(.white.opacity(0.5)).tracking(1)
                          }
                          .padding(.bottom, 30)
                      }
                  }
                  // Native Translation Logic
                  .translationTask(config) { session in
                      do {
                          let r = try await session.translate(text)
                          result = r.targetText
                          haptic.impactOccurred()
                          speak(result)
                          addToHistory(original: text, translated: result)
                      } catch { print(error) }
                  }
              }

              // Actions
              func toggleMic() {
                  haptic.impactOccurred()
                  if isListening {
                      isListening = false
                      speech.stop()
                      if !text.isEmpty {
                          // Start Translation
                          config = .init(source: .init(identifier: "en"), target: .init(identifier: "ja"))
                      }
                  } else {
                      text = ""; result = ""; isListening = true
                      speech.start { t in text = t }
                  }
              }

              func speak(_ t: String) {
                  let u = AVSpeechUtterance(string: t)
                  u.voice = AVSpeechSynthesisVoice(language: "ja-JP")
                  u.rate = 0.5
                  voice.speak(u)
              }
              
              func addToHistory(original: String, translated: String) {
                  struct Item: Codable { let original: String; let translated: String }
                  var list = (try? JSONDecoder().decode([Item].self, from: historyJSON.data(using: .utf8)!)) ?? []
                  list.insert(Item(original: original, translated: translated), at: 0)
                  if let data = try? JSONEncoder().encode(list) { historyJSON = String(data: data, encoding: .utf8) ?? "[]" }
              }
          }

          // --- HISTORY SCREEN ---
          struct HistoryScreen: View {
              @AppStorage("history_json") private var historyJSON = "[]"
              
              var body: some View {
                  NavigationView {
                      ZStack {
                          Color.black.ignoresSafeArea()
                          ScrollView {
                              VStack(spacing: 12) {
                                  let list = (try? JSONDecoder().decode([HItem].self, from: historyJSON.data(using: .utf8)!)) ?? []
                                  ForEach(list, id: \.translated) { item in
                                      HStack {
                                          VStack(alignment: .leading) {
                                              Text(item.original).font(.caption).foregroundStyle(.gray)
                                              Text(item.translated).font(.headline).foregroundStyle(.white)
                                          }
                                          Spacer()
                                      }
                                      .padding()
                                      .background(Color.white.opacity(0.1))
                                      .cornerRadius(12)
                                  }
                              }.padding()
                          }
                      }
                      .navigationTitle("History")
                      .navigationBarTitleDisplayMode(.inline)
                  }
              }
              struct HItem: Codable { let original: String; let translated: String }
          }

          // --- SPEECH MANAGER ---
          class NeuralMic {
              let r = SFSpeechRecognizer(locale: Locale(identifier: "en-US"))
              var req: SFSpeechAudioBufferRecognitionRequest?
              var task: SFSpeechRecognitionTask?
              let eng = AVAudioEngine()
              
              func start(on: @escaping (String)->Void) {
                  let session = AVAudioSession.sharedInstance()
                  try? session.setCategory(.record, mode: .measurement, options: .duckOthers)
                  try? session.setActive(true)
                  
                  req = SFSpeechAudioBufferRecognitionRequest()
                  req?.requiresOnDeviceRecognition = true
                  let node = eng.inputNode
                  node.installTap(onBus: 0, bufferSize: 1024, format: node.outputFormat(forBus: 0)) { b, _ in self.req?.append(b) }
                  eng.prepare()
                  try? eng.start()
                  task = r?.recognitionTask(with: req!) { res, _ in if let res = res { on(res.bestTranscription.formattedString) } }
              }
              func stop() { eng.stop(); eng.inputNode.removeTap(onBus: 0); req?.endAudio(); task?.cancel() }
          }
          EOF

      # ---------------------------------------------------
      # 2. GENERATE CONFIG
      # ---------------------------------------------------
      - name: Write Config
        run: |
          echo '{"name":"KotoAI","targets":{"KotoAI":{"type":"application","platform":"iOS","deploymentTarget":"18.0","sources":["App.swift"],"settings":{"PRODUCT_BUNDLE_IDENTIFIER":"com.koto.ai","CODE_SIGNING_ALLOWED":"NO"},"info":{"path":"Info.plist","properties":{"NSMicrophoneUsageDescription":"Mic","NSSpeechRecognitionUsageDescription":"Speech"}}}}}' > project.json
          echo '<?xml version="1.0"?><!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd"><plist version="1.0"><dict></dict></plist>' > Info.plist

      # ---------------------------------------------------
      # 3. BUILD
      # ---------------------------------------------------
      - name: Build
        run: |
          brew install xcodegen
          xcodegen generate --spec project.json
          xcodebuild archive -project KotoAI.xcodeproj -scheme KotoAI -configuration Release -archivePath build.xcarchive CODE_SIGNING_ALLOWED=NO CODE_SIGNING_REQUIRED=NO
          mkdir Payload
          cp -r build.xcarchive/Products/Applications/KotoAI.app Payload/
          zip -r KotoAI.ipa Payload

      - uses: actions/upload-artifact@v4
        with:
          name: KotoAI-Premium
          path: KotoAI.ipa


